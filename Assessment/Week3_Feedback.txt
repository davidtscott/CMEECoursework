Starting weekly assessment for David, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 44.30 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week6, Week1, Week7, Assessment, Week5, Week2, Week4, .git, Week3

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************

# Compiled source #
###################
*.com
*.class
*.dll
*.exe
*.o
*.so
*.aux

# Packages #
############
# it's better to unpack these files and commit the raw source
# git has its own built in compression methods
*.7z
*.dmg
*.gz
*.iso
*.jar
*.rar
*.tar
*.zip

*.pdf

# Logs and databases #
######################
*.log
*.sql
*.sqlite

# OS generated files #
######################
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db



###python##
*.pyc
__pycache__/*

__pycache__

#jupyernotebok
.ipynb_checkpoints

##################### R ################
# History files
.Rhistory
.Rapp.history

# Session Data files
.RData

# Example code in package build process
*-Ex.R

# Output files from R CMD build
/*.tar.gz

# Output files from R CMD check
/*.Rcheck/

# RStudio files
.Rproj.user/

##
README.html

### week ###################
MiniProject/
Week9/
C_Week10/



# anyfile above 10mb
./Week5/Data/EU/g250_06.tif
./Week5/Data/EU/bio1_15.tif
./Week5/Data/EU/bio1_16.tif
./Week5/Data/EU/bio12_15.tif
./Week5/Data/EU/bio12_16.tif
./Week5/Data/SRTM_Channels_network/SRTM_Channels_network.dbf
./Week5/Data/SRTM_Channels_network/SRTM_Channels_network.shp
./Week5/Data/SAFE_layout_shapefiles/sloperaster.tif
./Week5/Data/Borneo/MODIS_red_reflectance.tif
./Week5/Data/Borneo/MODIS_blue_reflectance.tif
./Week5/Data/Borneo/MODIS_NIR_reflectance.tif
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# README Document for CMEECourseWork Repository
## Author: David Scott - _david.scott18@imperial.ac.uk_
## Date: _OCT - NOV - DEC - 2018_

### For full course notes check out [The Multilingual Quantitative Biologist!](http://nbviewer.jupyter.org/github/mhasoba/TheMulQuaBio/blob/master/notebooks/Index.ipynb)
### Data and other resources are available at [TheMulQuaBio](https://mhasoba.github.io/TheMulQuaBio/) repository!

#### Description: 
Repository contains an individual directory for each weeks coursework, each further subdivided into four sub-directories; Code, Data, Results and Sandbox. Set working directory to Code. All scripts call data and output results to respective directories using relative paths. All scipts are annotated where appropriate.

#### Map of directories:
```
.
├── README.md
├── Assesment
├── Week1                 Unix & Shell Scripting
├── Week2                 Biological Computing in Python-1
├── Week3                 Biological Computing in R and Data Management Exploration & Visualisation in R 
|── Week4                 Statistics in R
├── Week5                 GIS
├── Week6                 Genomics & Bioinformatics
└── Week7                 Biological Computing in Python-2
    ├── Code
    ├── Data
    ├── Sandbox
    └── Results

8 directories

```
**********************************************************************

======================================================================
Looking for the weekly directories...

Found 7 weekly directories: Week1, Week2, Week3, Week4, Week5, Week6, Week7

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: Code, Data, Sandbox, Results

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# README Document for CMEECourseWork Week3
## Author: David Scott - _david.scott18@imperial.ac.uk_
## Date: _OCT - 2018_

### Biological Computing in R 
### Data Management, Exploration & Visualisation in R 

#### Description: 
All R scipts were written with R studio. Scripts are stored in the Code directory and use relative paths to call data from the Data directory and all outputs are directed to the Results directory. Thus, set working directory to Code. 

#### NOTE: 
Data for **GPDDmap.R** and **TAutoCorr.R** were not pushed as they are .RData format. Available on request. 

#### Packages: 
ggplot2, tidyr, dplyr, plyr, lattice.

#### Map of directories with short description of each script:
```
.
├── Code
│   ├── apply1.R :                                    Use of apply function '
│   ├── apply2.R :                                    Use of apply function '
│   ├── basic_io.R :                                  A simple script to illustrate R input-output '
│   ├── boilerplate.R :                               Example boilerplate in R '
│   ├── break.R :                                     Use of break in functions '
│   ├── browse.R :                                    Use of browse function '
│   ├── control.R :                                   Example of control flow constructs in R '
│   ├── DataWrang.R :                                 Wrangling data with base R and reshape2 package '
│   ├── DataWrangTidy.R :                             Data wrangling in R with tidyr and dplyr '
│   ├── get_TreeHeight.py :                           Calculates tree height using trigonometric function in python
│   ├── get_TreeHeight.R :                            Trigonometric function to calculate tree height  in R '
│   ├── Girko.R :                                     Girko's Law Simulation "
│   ├── GPDDmap.R :                                   Creates a world map and plots data points using maps package '
│   ├── MyBars.R :                                    Annotating Histogram '
│   ├── next.R :                                      Use of next in R functions '
│   ├── plotLin.R :                                   Mathematical Annotation '
│   ├── PP_Lattice.R :                                Lattice graphs with mean and median calc. by factor  '
│   ├── PP_Regress_loc.R :                            Linear regession . Faceted by 3 variables.  '
│   ├── PP_Regress.R :                                Linear Regression with plots. Faceted by 2 variables '
│   ├── preallocate.R :                               Vetorization example '
│   ├── run_get_TreeHeight.sh :                       Runs R and python3 scripts (both cal. tree height) '
│   ├── Run_Vectorize.sh :                            Compares speed of functions with and without vectorization(R & Python) '
│   ├── sample.R :                                    Run a simulation that involves sampling from a population '
│   ├── TAutoCorr.R :                                 Calculates autocorrelation of time series mean temperature data '
│   ├── TAutoCorr.tex :                               Time Series Autocorrelation of Key West Yearly Mean Tempertures (1901 - 2000) '
│   ├── TreeHeight.R :                                Trigonometric function to calculate tree height  '
│   ├── try.R :                                       Runs a simulation that involves sampling from a population with try '
│   ├── Vectorize1.py :                               Compares speed of two functions with and without vectorization
│   ├── Vectorize1.R :                                Sums all elements of a matrix  '
│   ├── Vectorize2.py :                               Compares speed of two Stochastic Ricker models with and without Vectorization
│   └── Vectorize2.R :                                Stochastic (Gaus.) Ricker Eqn with and without vectorization '
├── Data
│   ├── EcolArchives-E089-51-D1.csv
│   ├── GPDDFiltered.RData                          .gitignored
│   ├── KeyWestAnnualMeanTemperature.RData          .gitignored
│   ├── PoundHillData.csv
│   ├── PoundHillMetaData.csv
│   ├── Results.txt
│   └── trees.csv
├── README.tmp
├── Results
│   ├── Girko.pdf                                   .gitignored
│   ├── MyData.csv                                  .gitignored
│   ├── MyLinReg.pdf                                .gitignored
│   ├── PP_Regress.pdf                              .gitignored
│   ├── PP_Regress_Results.csv                      .gitignored
│   ├── PP_Results.csv                              .gitignored
│   ├── Pred_Lattice.pdf                            .gitignored
│   ├── Prey_Lattice.pdf                            .gitignored
│   ├── Rplots.pdf                                  .gitignored
│   ├── SizeRatio_Lattice.pdf                       .gitignored
│   ├── TAutoCorr_Histogram.pdf                     .gitignored
│   ├── TreeHts.csv                                 .gitignored
│   └── trees_treeheights.csv                       .gitignored
└── Sandbox

4 directories, 52 files

```
**********************************************************************

Found following files in results directory: TreeHts.csv, PP_Results.csv, PP_Regress_loc_Results.csv, trees_treeheights.csv, Pred_Lattice.pdf, Prey_Lattice.pdf, .gitignore, SizeRatio_Lattice.pdf, MyBars.pdf, MyData.csv...
ideally, Results directory should be empty other than, perhaps, a readme. 

Found 31 code files: browse.R, PP_Regress.R, Vectorize2.py, apply1.R, sample.R, run_get_TreeHeight.sh, get_TreeHeight.py, boilerplate.R, TreeHeight.R, PP_Lattice.R, next.R, Girko.R, Vectorize1.R, break.R, plotLin.R, basic_io.R, Vectorize1.py, try.R, apply2.R, get_TreeHeight.R, TAutoCorr.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, PP_Regress_loc.R, DataWrang.R, TAutoCorr.tex, MyBars.R, GPDDmap.R, control.R, Run_Vectorize.sh

======================================================================
Testing script/code files...

======================================================================
Inspecting script file browse.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: use of browse function

rm(list=ls()) # clears workspace

Exponential <- function(N0 = 1, r = 1, generations = 10){
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations)    # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations){
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return (N)
}

plot(Exponential(), type="l", main="Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 

**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.11808s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 29 2018
# Description: Linear Regression with plots. Faceted by 2 variables

rm(list = ls()) #clears workspaces
graphics.off() #clears any images

## Packages ##
library(ggplot2)
library(plyr)
library(dplyr)

# read data from file to dataframe
MyDF <- read.csv("../Data/EcolArchives-E089-51-D1.csv", stringsAsFactors=FALSE)

# convect prey.mass data units to mg
# must divide by 1000  to convert from grams to milligrams
MyDF <- MyDF %>% rowwise() %>% mutate(Prey.mass = 
        ifelse(Prey.mass.unit == "mg", Prey.mass/1000, Prey.mass))

#initiate plot and assign data to variables
#subset graph by Type of feeding interactio and colour by Predator.lifestage
p <- ggplot(MyDF, aes(x = Prey.mass, y = Predator.mass, colour = Predator.lifestage)) +
      facet_grid(rows = vars(Type.of.feeding.interaction))

# add points of shape 3(crosses) and regression lines with standard er. 
# adjusted length and width of line.
p <- p + geom_point(shape = 3) + geom_smooth(method = "lm", se=TRUE, fullrange=TRUE, size = 0.5) 

# changed x and y axis to log10 and added labels
p <- p + scale_x_log10() + scale_y_log10() + xlab("Prey Mass in grams") + ylab("Predator mass in grams") 

# changes theme to black and white
# moves legned to bottom and displays in one row
p <- p + theme_bw() + theme(legend.position = "bottom") + guides(colour = guide_legend(nrow = 1))

# Open blank pdf page using a relative path
pdf("../Results/PP_Regress.pdf", 11.7, 8.3)
print(p)
dev.off()
#calculate reg results for fitted lines in each subset of data 
#fitted_models <- MyDF %>% group_by(Type.of.feeding.interaction, Predator.lifestage)
#                          %>% do(model = lm(Predator.mass ~ Prey.mass, data = .))

#fitted_models$model
#library(broom)
#a <- fitted_models %>% tidy(model) 
#b <- fitted_models %>% glance(model) 


## calculate reg results for fitted lines in each subset of data 
LinearOutput <- dlply(MyDF,.(Type.of.feeding.interaction, Predator.lifestage), function(x) lm(Predator.mass~Prey.mass, data = x))

# Extract Coeffieciets r2, intercept, slope and p value
CoefOut <- ldply (LinearOutput, function(x) {
  intercept <- summary(x)$coefficients[1]
  slope <- summary(x)$coefficients[2]
  p.value <- summary(x)$coefficients[8]
  r2 <- summary(x)$r.squared
  data.frame(r2, intercept, slope, p.value)})

# Extract F statistic
F.statistic <- ldply(LinearOutput, function(x) summary(x)$fstatistic[1])

# Merge F stat with rest of coefficients into one dataframe
OutputDF <- merge(CoefOut, F.statistic, by = c("Type.of.feeding.interaction", "Predator.lifestage"), all = TRUE)

# change name of 7th columm
names(OutputDF)[7] <- "F.statistic"

# write results to a csv file in the results directory 
write.csv(OutputDF, "../Results/PP_Regress_Results.csv", row.names = FALSE, quote = FALSE)

#?write.csv
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error:

Attaching package: ‘dplyr’

The following objects are masked from ‘package:plyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Error in facet_grid(rows = vars(Type.of.feeding.interaction)) : 
  unused argument (rows = vars(Type.of.feeding.interaction))
Execution halted

======================================================================
Inspecting script file Vectorize2.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: October 2018

"""
Compares speed of two Stochastic Ricker models with and without
Vectorization.
""" 

__appname__ = '[Vectorize2.py]'
__author__ = 'David Scott (david.scott18@imperial.ac.uk)'
__version__ = '0.0.1'
__license__ = "License for this code/program"

## imports ##
import numpy as np 
import time

## Stochastic Ricker Equation
def stochrick(p0= np.random.uniform(.5, 1.5, (1000)), \
              r=1.2, K=1, sigma=0.2, numyears=100):
    """ Stochasitic Ricker model with Gausiann fluctiation """
    N = np.full([numyears, len(p0)], np.nan)
    N[0,] = p0 
    for pop in range(1, p0):
        for yr in range(2, p0):
            N[yr, pop] = N[yr - 1, pop] * np.exp(r * (1 - N[yr - 1, pop] / K) \
                        + np.random.normal(0, sigma, len(p0)))
    return N 

# call function and record time taken to execute
# records run time imediately prior and post execution
start1 = time.time()
stochrick
end1 = time.time()

time1 = end1 - start1

# format print output with time taken
print("Stochastic Ricker takes:{}".format(time1))

## Vectorized Stochastic Ricker Equation 
def stochrickvect(p0= np.random.uniform(.5, 1.5, (1000)),\
                  r=1.2, K=1, sigma=0.2, numyears=100):
    """ Vectorized Stochasitic Ricker model with Gausiann fluctiation. 
    Does not loop through pop and pop has been removed from the model."""
    N = np.full([numyears, len(p0)], np.nan)
    N[0,] = p0 
    # removed the pop loop
    for yr in range(2, p0):
        # removed pop from equation also
        N[yr,] = N[yr - 1,] * np.exp( r * (1 - N[yr - 1,] / K) \
                + np.random.normal(0,sigma, len(p0)))
    return N 

# call function and record time taken to execute 
# records run time imediately prior and post execution
start2 = time.time()
stochrickvect
end2 = time.time()

time2 = end2 - start2

# format print output with time taken
print("Vectorized Stochastic Ricker takes:{}".format(time2))
**********************************************************************

Testing Vectorize2.py...

Vectorize2.py is a Python script file;
 checking for docstrings...

Found one or more doctrings!

Output (only first 500 characters): 

**********************************************************************
Stochastic Ricker takes:7.152557373046875e-07
Vectorized Stochastic Ricker takes:4.76837158203125e-07

**********************************************************************

Code ran without errors

Time consumed = 0.13911s

======================================================================
Inspecting script file apply1.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: use of apply function

rm(list=ls()) # clears workspace

# use of *apply functions
# vectorise data for you 

## apply: applying the same function to rows/colums of a matrix

## Build a random matrix
M <- matrix(rnorm(100), 10, 10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)
**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 

**********************************************************************
 [1] -0.002728195  0.693950944 -0.395553959 -0.396748252  0.232676931
 [6] -0.013047973 -0.249194293 -0.134200116 -0.275946136  0.158668668
 [1] 0.7045280 0.8103325 0.9681902 0.5428772 0.5525828 0.5011575 1.1122655
 [8] 0.4972004 0.3153962 0.9423579
 [1]  0.09473327 -0.32726312 -0.37481749  0.04886511 -0.03369958 -0.02370968
 [7]  0.15614336 -0.09973586  0.10376432  0.07359729

**********************************************************************

Code ran without errors

Time consumed = 0.07293s

======================================================================
Inspecting script file sample.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: run a simulation that involves sampling from a population

rm(list=ls()) # clears workspace


x <- rnorm(50) #Generate your population
doit <- function(x){
  x <- sample(x, replace = TRUE)
  if(length(unique(x)) > 30) { #only take mean if sample was sufficient
    print(paste("Mean of this sample was:", as.character(mean(x))))}
  }

## Run 100 iterations using vectorization:
result <- lapply(1:100, function(i) doit(x))

## Or using a for loop: 
result <- vector("list", 100) #Preallocate/Initialize
for(i in 1:100){
  result[[i]] <- doit(x)
}
**********************************************************************

Testing sample.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Mean of this sample was: 0.00641500721409499"
[1] "Mean of this sample was: -0.123774503682579"
[1] "Mean of this sample was: -0.183454309302371"
[1] "Mean of this sample was: -0.147295888201565"
[1] "Mean of this sample was: -0.0560234092043281"
[1] "Mean of this sample was: -0.0256999769825606"
[1] "Mean of this sample was: -0.136393539269919"
[1] "Mean of this sample was: -0.174797456510313"
[1] "Mean of this sample was: 0.0291387897657314"
[1] "Mean of this sample was: -0.158041013036445
**********************************************************************

Code ran without errors

Time consumed = 0.10607s

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:
**********************************************************************
#!/bin/bash
# Author: David Scott David.Scott18@imperial.ac.uk
# Script: boilerplate.sh
# Desc: runs rscript and python3 scripts (both cal. tree height)
# Arguments: none
# Date: Oct 2018

echo "Running get_TreeHeight.R in R"
Rscript --vanilla get_TreeHeight.R ../Data/trees.csv
echo -e "get_TreeHeight.R is complete. \n"


echo "Running get_TreeHeight.py in python3"
python3 get_TreeHeight.py ../Data/trees.csv
echo "get_TreeHeight.py is complete"
**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 

**********************************************************************
Running get_TreeHeight.R in R
[1] "Saved output to csv file: ../Results/trees_treeheights.csv"
get_TreeHeight.R is complete. 

Running get_TreeHeight.py in python3
Saved output to csv file: ../Results/trees_treeheights.csv
get_TreeHeight.py is complete

**********************************************************************

Code ran without errors

Time consumed = 0.12075s

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: October 2018

""" Calculates tree height using trigonometric function in python""" 

__appname__ = '[get_TreeHeight.py]'
__author__ = 'David Scott (david.scott18@imperial.ac.uk)'
__version__ = '0.0.1'
__license__ = "License for this code/program"

## imports ##
import sys
import csv
import math
import os

## functions ##

def command_line_data(argv):
    """ creates an array from input file given in command line. 
    If none given, exits script and prints execution failure message. 
    retunrs array without headers
    """
    # if no file given exit script
    if (len(sys.argv) == 1):
        sys.exit("SCRIPT EXECUTION STOPPED: One input file must be supplied")
    # if there is make array but skip header row
    with open(sys.argv[1], 'r') as f:
        treedata = csv.reader(f)
        next(treedata)
        TreeArray = [row for row in treedata]
        return TreeArray

#create function to calculate height
def tree_height(degrees, distance): 
    """Calculates heights of trees given distance of each tree 
    from its base and angle to its top, using  the trigonometric formula """
    radians = degrees * math.pi / 180 # degrees
    height = distance * math.tan(radians) # distace 
    #print("Calculated heights in meters are:")
    return(height)

def main(argv):
    """ Call tree_height and command_line_data functions and outputs results 
    to csv file in results directory, using input file name. 
    """
    # call command_line_data function 
    AllData = command_line_data(sys.argv)
    # apply tree_height function to each row in array and append results to new column
    for row in range(len(AllData)):
        AllData[row].append(tree_height(float(AllData[row][2]), float(AllData[row][1])))

    # take elements from command line input file and add to output filename
    name = str(os.path.basename(os.path.splitext(sys.argv[1])[0]))
    outputfilename = "../Results/" + name + "_treeheights.csv"

    #write to a csv file and add headers
    with open("outputfilename", "w") as g:
        writer = csv.writer(g)
        writer.writerow(("Species", "Distance.m", "Angel.degrees", "Tree.Height.m"))
        for row in AllData:
            writer.writerow(row)
        print("Saved output to csv file: {}" .format(outputfilename))
        # prints output file name and path to file

if __name__ == "__main__":
    status = main(sys.argv)
    sys.exit(status)


###
### alternative method below. decided to change it to make more use of functions etc 
###

# read distance, degrees and species names data into lists
#distance = []
#degrees = []
#names = []

#with open(sys.argv[1], 'r') as f:
    #next(f)             # skips header
    #for row in treedata:
        #names.append(row[0])
        #distance.append(float(row[1])) # import items to lst as floats
        #degrees.append(float(row[2]))

#create function to calculate height
#def tree_height(degrees, distance): #(treedata): 
    #"""Calculates heights of trees given distance of each tree 
    #from its base and angle to its top, using  the trigonometric formula """
    #heights = []
    #for i, j in zip(degrees, distance):
        #radians = i * math.pi / 180 # degrees (i) 
        #heights.append(j * math.tan(radians)) # distance (j)
    #print("Calculated heights in meters are:")
    #return(heights)

# call tree_height function with input parameters 
#   and joins lists of parameters with output tree heights 
#rows = zip(names, distance, degrees, tree_height(degrees, distance))

# take elements from command line input file and add to output filename
#name = str(os.path.basename(os.path.splitext(sys.argv[1])[0]))
#outputfilename = "../Results/" + name + "_treeheights.csv"

#write to a csv file and add headers
#with open("outputfilename", "w") as g:
    #writer = csv.writer(g)
    #writer.writerow(("Species", "Distance.m", "Angel.degrees", "Tree.Height.m"))
    #for row in rows:
        #writer.writerow(row)
    #print("Saved output to csv file: {}" .format(outputfilename))
    # prints output file name and path to file
    **********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;
 checking for docstrings...

Found one or more doctrings!

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error:
SCRIPT EXECUTION STOPPED: One input file must be supplied

======================================================================
Inspecting script file boilerplate.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Example boilerplate in R

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

# A boilerplate R script 

MyFunction <- function(Arg1, Arg2){
    # Statements involving Arg1, Arg2:
    print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
    print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
    
    return (c(Arg1, Arg2)) #this is optional, but very useful 
}

MyFunction(1,2) #test the function
MyFunction("Riki", "Tiki") #A different test

# {} brackets tell R where specification of function start and end
# indentation not required like in python
#   but make code more readable
**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.08560s

======================================================================
Inspecting script file TreeHeight.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Trigonometric function to calculate tree height 

rm(list=ls()) # clears workspace
graphics.off() # clears graphics


# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"


# import data with headers
# using read.csv function. File path goes to Data directory
MyData <- read.csv("../Data/trees.csv", header = TRUE)


#functin using degrees to calculate radians 
#   and radian with distance to calculate height. 
TreeHeight <- function(degrees, distance){
    radians <- degrees * pi / 180
    height <- distance * tan(radians)
    #print(paste("Tree height is:", height))
    return (height)
}

#creates a data frome (TreeDF) with data from 
# MyData (imported at beginning from trees.csv)
# and calls function TreeHeight defined above
# calls it with MyData column 3 (degrees) and MyData column 2 (distance)
# and thus appends output of function from two inputs with MyData
TreeDF <- data.frame(MyData, TreeHeight(MyData[3], MyData[2]))
colnames(TreeDF)[4] <- "Tree.Height.m"
# names column 4 containing output of function as "Tree.Height.m"

write.csv(TreeDF, "../Results/TreeHts.csv", row.names = FALSE)
print("Results saved to '../Results/TreeHts.csv'")
#write TreeDF data frame to a csv file called TreeHts.csv in Results directory
# does not include row names

# {} curly brackets required for multi line statements.
**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Results saved to '../Results/TreeHts.csv'"

**********************************************************************

Code ran without errors

Time consumed = 0.07808s

======================================================================
Inspecting script file PP_Lattice.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 26 2018
# Description: Lattice graphs with mean and median calc. by factor 

rm(list = ls()) # clears workspace
graphics.off() # closes all open graphics

## Packages ##
library(lattice)
library(plyr)
library(dplyr)
require(tidyr)

## load data
MyDF <- read.csv("../Data/EcolArchives-E089-51-D1.csv")

## examine dataframe
# dim(MyDF)
# str(MyDF)
# head(MyDF)
# names(MyDF)

## draws and saves three lattic graphs by feding interaction type
# use of log of masses (or mass-ratios) for all three

## predator mass:   Pred_Lattice.pdf
pdf("../Results/Pred_Lattice.pdf") #11.7, 8.3) 
# Open blank pdf page using a relative path and specifies page dimensions in inches
print(densityplot(~log(Predator.mass) | Type.of.feeding.interaction, data=MyDF, 
    xlab="Log Predator Mass (g)", main="Density Plot by Feeding Interaction Type", col="purple"))
dev.off()         

## prey mass:      Prey_Lattice.pdf
pdf("../Results/Prey_Lattice.pdf") # 11.7, 8.3) 
print(densityplot(~log(Prey.mass) | Type.of.feeding.interaction, data=MyDF,
    main= "Density Plot by Feeding Interaction Type", xlab="Log Prey Mass (g)", col="purple"))
     # scales=list(cex=1.2, col="red")
dev.off() 

## size ratio of predator mass over prey mass:   SizeRatio_Lattice.pdf
pdf("../Results/SizeRatio_Lattice.pdf") # 11.7, 8.3) 
print(densityplot(~(log(Predator.mass/Prey.mass)) | Type.of.feeding.interaction, data=MyDF,
    main= "Density Plot by Feeding Interaction Type", xlab="Log Pred/Prey Size Ratio (g)", col="purple"))
dev.off()

# Calculated mean and meadian log pred mass, prey mass, and pred prey size ratio, by feeding type

## Mean and median of log predator mass
#Mean
LogPredMean <- ddply(MyDF, .(Type.of.feeding.interaction), summarize, Pred.Mean=mean(log(Predator.mass)))
#Median
LogPredMedian <- ddply(MyDF, .(Type.of.feeding.interaction), summarize, Pred.Median=median(log(Predator.mass)))
#join both
LogPred <- join(LogPredMean, LogPredMedian, type ="inner")

## Mean and median of log prey mass
LogPreyMean <- ddply(MyDF, .(Type.of.feeding.interaction), summarize, Prey.Mean=mean(log(Prey.mass)))
LogPreyMedian <- ddply(MyDF, .(Type.of.feeding.interaction), summarize, Prey.Median=median(log(Prey.mass)))
LogPrey <- join(LogPreyMean, LogPreyMedian, type ="inner")

# join median and mean of log prey with that of log predator
LogPredPrey <- join(LogPred, LogPrey, type ="inner")

# Mean and median of log ratio mass
LogRatioMean <- ddply(MyDF, .(Type.of.feeding.interaction), summarize, Pred.Prey.Ratio.Mean=mean(log(Predator.mass/Prey.mass)))
LogRatioMedian <- ddply(MyDF, .(Type.of.feeding.interaction), summarize, Pred.Prey.Ratio.Median=median(log(Predator.mass/Prey.mass)))
LogRatio <- join(LogRatioMean, LogRatioMedian, type ="inner")

# join previous two joined with that fo ration. Created final dataframe
LogDF <- join(LogPredPrey, LogRatio, type ="inner")
#print(LogDF)
# output results to a csv
write.csv(LogDF, "../Results/PP_Results.csv", row.names = FALSE)
**********************************************************************

Testing PP_Lattice.R...

Output (only first 500 characters): 

**********************************************************************
null device 
          1 
null device 
          1 
null device 
          1 

**********************************************************************

Encountered error:

Attaching package: ‘dplyr’

The following objects are masked from ‘package:plyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loading required package: tidyr
Joining by: Type.of.feeding.interaction
Joining by: Type.of.feeding.interaction
Joining by: Type.of.feeding.interaction
Joining by: Type.of.feeding.interaction
Joining by: Type.of.feeding.interaction

======================================================================
Inspecting script file next.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Use of next in R functions

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

# example of 'next'
for (i in 1:10) {
  if ((i %% 2) == 0)
    next # pass to next iteration of loop
  print(i)
}
**********************************************************************

Testing next.R...

Output (only first 500 characters): 

**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.08640s

======================================================================
Inspecting script file Girko.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 29 2018
# Description: Girko's Law Simulation

rm(list = ls()) 
graphics.off() 

## packages##
library(ggplot2)

# function that returns an ellipse
build_ellipse <- function(hradius, vradius){ 
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

# Assign size of the matrix
N <- 250 

# Build the matrix
M <- matrix(rnorm(N * N), N, N) 

# Find the eigenvalues
eigvals <- eigen(M)$values 

# Build a dataframe
eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) 

# The radius of the circle is sqrt(N)
my_radius <- sqrt(N) 

# Dataframe to plot the ellipse
ellDF <- build_ellipse(my_radius, my_radius) 

# rename the columns
names(ellDF) <- c("Real", "Imaginary") 

# Plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p + geom_point(shape = I(3)) + theme(legend.position = "none")

# Add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# Add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))

# Save as pdf, Open blank pdf page using a relative path
pdf("../Results/Girko.pdf") 
print(p)
graphics.off() 
**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 1.15667s

======================================================================
Inspecting script file Vectorize1.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: sums all elements of a matrix 

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

# creates matix of uniform distribution 
M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M){
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]){
    for (j in 1:Dimensions[2]){
      Tot <- Tot + M[i,j]
    }
  }
  return (Tot)
}

## This on my computer takes about 1 sec
print("Speed of SumAllElements function defined using loops:")
print(system.time(SumAllElements(M)))

## While this takes about 0.01 sec
print("Speed of sum function without loops:")
print(system.time(sum(M)))

#system.time function calculates time taken by code
#sum() function 100 times faster than SumAllElements()
# as it uses vectorisation, avoiding the amount of loops used by SumAllElements
**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Speed of SumAllElements function defined using loops:"
   user  system elapsed 
  0.080   0.004   0.084 
[1] "Speed of sum function without loops:"
   user  system elapsed 
  0.004   0.000   0.002 

**********************************************************************

Code ran without errors

Time consumed = 0.22357s

======================================================================
Inspecting script file break.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Use of break in functions

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

i <- 0 #initialize i
  while(i < Inf) {
    if (i == 20) {
      break
      } # Break out of the while loop!
    else {
      cat("i equals " , i , " \n")
      i <- i + 1 # Update i
    }
  }
**********************************************************************

Testing break.R...

Output (only first 500 characters): 

**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  
i equals  10  
i equals  11  
i equals  12  
i equals  13  
i equals  14  
i equals  15  
i equals  16  
i equals  17  
i equals  18  
i equals  19  

**********************************************************************

Code ran without errors

Time consumed = 0.09187s

======================================================================
Inspecting script file plotLin.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 29 2018
# Description: Mathematical Annotation

rm(list = ls()) 
graphics.off() 

## packages ##
library(ggplot2)

# create data
x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                   parse = TRUE, size = 6, 
                   colour = "blue")

#save plot
pdf("../Results/MyLinReg.pdf") # Open blank pdf page using a relative path
print(p)
graphics.off() 
**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 1.01085s

======================================================================
Inspecting script file basic_io.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: A simple script to illustrate R input-output

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

# Run line by line and check inputs outputs to understand what is happening

# import with headers
MyData <- read.csv("../Data/trees.csv", header = TRUE) 

#write it out as a new file
write.csv(MyData, "../Results/MyData.csv") 

# Append to it 
write.table(MyData[1,], file = "../Results/MyData.csv", append=TRUE, col.names = FALSE) 

# write row names
write.csv(MyData, "../Results/MyData.csv", row.names = TRUE) 

 # ignore column names
write.table(MyData, "../Results/MyData.csv", col.names = FALSE) 
**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.07554s

======================================================================
Inspecting script file Vectorize1.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: October 2018

""" Compares speed of two functions with and without vectorization""" 

__appname__ = '[Vectorize1.py]'
__author__ = 'David Scott (david.scott18@imperial.ac.uk)'
__version__ = '0.0.1'
__license__ = "License for this code/program"

## imports ##
import numpy as np 
import time

# creates random array of dimension 1000 * 10000
#   with uniform distribution
M = np.random.rand(1000, 1000)

# define function to count each element of array M
def SumAllElements(M):
    """Counts sum of elements of an array """
    tot = 0
    for i in np.nditer(M): 
        tot += i
    return tot

## Call SumAllElements function with input and timeit 
start1 = time.time()  # starts timer
SumAllElements(M) #calls function with input
end1 = time.time()  # ends timer

## Call sum function with input and timeit 
# sum function does that same as above but without loops
start2 = time.time() # starts timer
np.sum(M)
end2 = time.time() # ends timer

# print speed of functiosn to compare
print("Speed of SumAllElements function using loops: {}".format(end1 - start1)) 
print("Speed of sum function without loops: {}".format(end2 - start2)) 
**********************************************************************

Testing Vectorize1.py...

Vectorize1.py is a Python script file;
 checking for docstrings...

Found one or more doctrings!

Output (only first 500 characters): 

**********************************************************************
Speed of SumAllElements function using loops: 0.18506431579589844
Speed of sum function without loops: 0.0006499290466308594

**********************************************************************

Code ran without errors

Time consumed = 0.33826s

======================================================================
Inspecting script file try.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: run a simulation that involves sampling from a population with try

rm(list=ls()) # clears workspace


x <- rnorm(50) #Generate your population
doit <- function(x){
  x <- sample(x, replace = TRUE)
  if(length(unique(x)) > 30) {#only take mean if sample was sufficient
    print(paste("Mean of this sample was:", as.character(mean(x))))
  } 
  else {
    stop("Couldn't calculate mean: too few unique points!")
  }
}

## Try using "try" with vectorization:
result <- lapply(1:100, function(i) try(doit(x), FALSE))

## Or using a for loop:
result <- vector("list", 100) #Preallocate/Initialize
for(i in 1:100) {
  result[[i]] <- try(doit(x), FALSE)
}
**********************************************************************

Testing try.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Mean of this sample was: -0.0683420854628051"
[1] "Mean of this sample was: -0.200707878548745"
[1] "Mean of this sample was: 0.0473849683320328"
[1] "Mean of this sample was: -0.138686958710019"
[1] "Mean of this sample was: -0.0653026002566863"
[1] "Mean of this sample was: -0.262184989955165"
[1] "Mean of this sample was: -0.253170090837118"
[1] "Mean of this sample was: -0.266228727848891"
[1] "Mean of this sample was: -0.132773977978715"
[1] "Mean of this sample was: 0.0410443986538239"
**********************************************************************

Encountered error:
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!
Error in doit(x) : Couldn't calculate mean: too few unique points!

======================================================================
Inspecting script file apply2.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: use of apply function

rm(list=ls()) # clears workspace

SomeOperation <- function(v){ # if sum of v greaater than 0, multiply it by 100
  if (sum(v) > 0){
    return (v * 100)
  }
  return (v)
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))
**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 

**********************************************************************
            [,1]       [,2]      [,3]       [,4]        [,5]       [,6]
 [1,] -127.45366  0.1581136  56.30227 -40.366614 -2.02741123 -2.3683532
 [2,]  246.50364 -1.0766142 -23.13381 164.206105 -0.01808204 -0.3383343
 [3,]  -59.03964  1.1652120  75.04879 -31.117095 -0.32181052 -0.4899292
 [4,]  -72.94353 -1.1890746 -63.00155   2.611958 -1.09729365 -1.0874570
 [5,]   64.30431  0.6474271 -94.49395  46.315431  0.41178007 -0.3969970
 [6,]   46.48087 -0.9226244 -94.47889 -40.727542  1.37239336  0.57214
**********************************************************************

Code ran without errors

Time consumed = 0.08928s

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Calc. tree height: input file from command line, outputs to csv

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

## packages ##
library(tools)

args = commandArgs(trailingOnly=TRUE)
# enables command line arguments

# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"

# test if there is at least one argument given in command line: 
# if not, return an err
if (length(args)==0) {
  stop("At least one argument must be supplied (input file).", call.=FALSE)
} 

MyData <- read.csv(args[1], header = TRUE) # import with headers
#reads content of a csv file given in command line (argument one)
# assigns content to MyData variable

#functin using degrees to calculate radians 
#   and radian with distance to calculate height. 
TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)
  #print(paste("Tree height is:", height))
  return (height)
}

#creates a data frome (TreeDF) with data from MyData 
# and calls function TreeHeight defined above
# calls it with MyData column 3 (degrees) and MyData column 2 (distance)
# and thus appends output of function from two inputs with MyData
TreeDF <- data.frame(MyData, TreeHeight(MyData[3], MyData[2]))
colnames(TreeDF)[4] <- "Tree.Height.m"
# names column 4 containing output of function as "Tree.Height.m"


# strip extension and file path from file given as agrument one in command line
inputfile_name <- file_path_sans_ext(basename(args[1]))
# paste new file path , extension  together and assigns to variable
outputfile_name <- paste("../Results/", inputfile_name, "_treeheights.csv", sep = "")
# saves dataframe (TreeDF) to file named above.
write.csv(TreeDF, outputfile_name, row.names = FALSE)
#prints new name of output file
print(paste("Saved output to csv file:", outputfile_name))
**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error:
Error: At least one argument must be supplied (input file).
Execution halted

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Calculates autocorrelation of time series mean temperature data

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

######### AUTOCORRELATION #########
# autocorrelation to asses if time series (mean temp) is dependent on its past
# look at pairs. in this case 100 observations = 99 pairs
# pairs take form of (x[t],x[t-1]). t is observatin index, varies from 2 to 100 
# estimated sample correlation of these pairs is the lag-1 autocorrelation
#  of our data keytemps. 


## loads .RData from data directory into workspace
load("../Data/KeyWestAnnualMeanTemperature.RData")
# Temperature data from Key West, Florida for 21st Century (1901 to 2000)
TempData <- ats # assigns to variable TempData
# ats is automatic name for data from a .RData file
keytemps <- TempData[,2] 
# assigns each yearly mean temperature (without corresponding year)


#### create pairs of observations #####
# two vectors each of lenth n-1 (100 - 1)
#   thus rows are (x[t],x[t-1])

# Defines x_t0 as vector x[-1]
x_t0 <- keytemps[-1] 

# Defines x_t1 as vector x[-n]
x_t1 <- keytemps[-100]

## Confirms that x_t0 and x_t1 are (x[t], x[t-1]) pairs  
# head(cbind(x_t0, x_t1))
# plot(x_t0, x_t1)

## View the correlation between x_t0 and x_t1
# apply cor() function to estimate lag-1 autocorrelation 
autocor <- cor(x_t0, x_t1)
print(paste("lag -1 autocorrelation of mean temperatures:", autocor))

#########################################
### ALTERNTIVE METHOD ACF (not base R) ##
# Use acf with x
# lag.max = 1 creates a single lag period
# acf(keytemps, lag.max = 1, plot = FALSE)

# difference between method above and alternatve method
# Confirm that difference factor is (n-1)/n 
# cor(x_t1, x_t0) * (100-1)/100
##########################################


# function defined that creates (x[t],x[t-1]) pairs as above
# from keytemps and does so randomly generating random permutations
corfun <- function(keytemps){
  y_t0 <- sample(keytemps[-1], replace = TRUE)
  y_t1 <- sample(keytemps[-100], replace = TRUE)
  return(cor(y_t0, y_t1))
}

result <- lapply(1:10000, function(i) corfun(keytemps))
#  lapply function feeds corfun function 10,000 times with key temps data
# stores data for ech randomly permutated year sequence and stores it
result.numeric <- as.numeric(result)
# mutates results to numeric

# create and save histogram of results with heading and labels
pdf("../Results/TAutoCorr_Histogram.pdf")
hist(result.numeric, col="gray", xlab="AutoCorrelations",
                     main="KeyWest Mean Temperature Data (1901 - 2000)")
#add abline to show where the initial correlation fell inrelation to the 10000
abline(v = autocor, col = "red", lwd = 2)
dev.off() # close plot

pvalue =length(result.numeric[result.numeric > autocor])/length((result.numeric)) 
print(paste("Aproximate p-value:",  pvalue))
# calculates the fraction of result.numeric (result from 10,000 random permutations)
# greater than first autocorrelation (autocor)
# used as an approximate p - value

# By looking at the abline it appears the intial correlation result autocor) 
# falls within 5% confidence interval, thus 95% confident not random. 
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error:
Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
Calls: load -> readChar
In addition: Warning message:
In readChar(con, 5L, useBytes = TRUE) :
  cannot open compressed file '../Data/KeyWestAnnualMeanTemperature.RData', probable reason 'No such file or directory'
Execution halted

======================================================================
Inspecting script file Vectorize2.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date: October 2018
# Description: Stochastic (Gaus.) Ricker Eqn with and without vectorization

rm(list=ls()) # clears workspace 
graphics.off() # clears graphics

stochrick<-function(p0=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{                # runif here makes it stchastic
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  
  for (pop in 1:length(p0)) #loop through the populations
  {   # each rep of for loop, R has to re-size the vector and reallocate memory
    for (yr in 2:numyears) #for each pop, loop through the years
    {
      N[yr,pop]<-N[yr-1,pop]*exp(r*(1-N[yr-1,pop]/K)+rnorm(1,0,sigma))
    }
  }
  return(N)

}

print("Stochastic Ricker takes:")
print(system.time(stochrick()))

# Now write another function called stochrickvect that vectorizes the above 
# to the extent possible, with improved performance: 

# vectorised 


stochrickvect<-function(p0=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  for (yr in 2:numyears) #for each pop, loop through the years
  {
    N[yr,]<-N[yr-1,]*exp(r*(1-N[yr-1,]/K)+rnorm(1,0,sigma))
  }
  return(N)
}
# removed pop loop and removed it from equation.
# years = t

print("Vectorized Stochastic Ricker takes:")
print(system.time(stochrickvect()))
**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Stochastic Ricker takes:"
   user  system elapsed 
  0.248   0.000   0.246 
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.008   0.000   0.010 

**********************************************************************

Code ran without errors

Time consumed = 0.34086s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Data wrangling in R with tidyr and dplyr

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

## packages ##
require(dplyr)
require(tidyr)
require(reshape2) # load the reshape2 package

################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

## Script edited to use dplyr and tidyr packages 
##   instead of reshape2 and base R
# Old code left in to but hashed out, to show compare methodology

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../Data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../Data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############

#head(MyData) # prints first 6 rows and headers
dplyr::tbl_df(MyData) #like head()
#dim(MyData) # prints dimensions
dplyr::dim_desc(MyData) #like dim()
#str(MyData) # prints structure
dplyr::glimpse(MyData) #like str()
#fix(MyData) #you can also do this
utils::View(MyData) #same as fix()
#fix(MyMetaData)
utils::View(MyMetaData) #same as fix()

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
#head(MyData)
dplyr::tbl_df(MyData) #like head()
#dim(MyData)
dplyr::dim_desc(MyData) #like dim()

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

rownames(TempData) <- NULL  # removes row names
#head(TempData)
dplyr::tbl_df(TempData) #like head()
############# Convert from wide to long format  ###############

#?melt #check out the melt function
#?gather #check out the gather function from tidyr package

#MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")
MyWrangledData <- TempData %>% tidyr::gather(., Species, count, -Cultivation, -Block, -Plot, -Quadrat) %>% mutate(Cultivation = as.factor(Cultivation), Block = as.factor(Block), Plot = as.factor(Plot), Quadrat = as.factor(Quadrat), count = as.integer(count))
# pipes data from TempData to tidyr function gather (alternative to melt function)
# assigns variables, -
# pipe to mutate function and change them into factors and integer variables. 

# melt collapses daat in wide format and stacks it into singl column
#head(MyWrangledData); tail(MyWrangledData)
dplyr::tbl_df(MyWrangledData); tail(MyWrangledData)

# assign the correct data type of each row
#MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
#MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
#MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
#MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
#MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])
#as.factor creates a factor column

#str(MyWrangledData)
dplyr::glimpse(MyWrangledData) #like str()
#head(MyWrangledData)
dplyr::tbl_df(MyWrangledData) #like head()
#dim(MyWrangledData)
dplyr::dim_desc(MyWrangledData) #like dim()

############# Exploring the data (extend the script below)  ###############

# from plyr to dplyr
# from reshape2 to tidyr

dplyr::tbl_df(MyWrangledData) #like head()
dplyr::glimpse(MyWrangledData) #like str()
utils::View(MyWrangledData) #same as fix()
dplyr::filter(MyWrangledData, count > 100) #like subset()
dplyr::slice(MyWrangledData, 10:15) # Look at an arbitrary set of data rows
**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 

**********************************************************************
# A tibble: 45 x 60
   V1       V2     V3     V4    V5    V6    V7    V8    V9    V10   V11   V12  
   <chr>    <chr>  <chr>  <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>
 1 Cultiva… octob… octob… octo… octo… octo… may   may   may   may   may   march
 2 Block    a      a      a     a     a     a     a     a     a     a     a    
 3 Plot     1      1      1     1     1     2     2     2     2     2     3    
 4 Quadrat  Q1     Q2     Q3    Q4    Q5    Q1    Q2    Q3    Q4    Q5    Q1   
 
**********************************************************************

Encountered error:
Loading required package: dplyr

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Loading required package: tidyr
Loading required package: reshape2

Attaching package: ‘reshape2’

The following object is masked from ‘package:tidyr’:

    smiths


======================================================================
Inspecting script file preallocate.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date: October 2018
# Description: vetorization example

rm(list=ls()) # clears workspace

a <- NA
for (i in 1:100000) {
  a <- c(a, i)
}
print(a)
## This on my computer takes about 1 sec
print(system.time(SumAllElements(a)))
## While this takes about 0.01 sec
print(system.time(sum(a)))

########################

a <- rep(NA, 1000000)

for (i in 1:1000000) {
  a[i] <- i
}
print(a)
## This on my computer takes about 1 sec
print(system.time(SumAllElements(a)))
## While this takes about 0.01 sec
print(system.time(sum(a)))
**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 10.00426s

======================================================================
Inspecting script file PP_Regress_loc.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 31 2018
# Description: Linear regession . Faceted by 3 variables. 

rm(list = ls()) 
graphics.off() 

## Packages
library(plyr)
library(dplyr)

# read data from file to dataframe
MyDF <- read.csv("../Data/EcolArchives-E089-51-D1.csv", stringsAsFactors=FALSE)

# convect prey.mass data units to mg
# must divide by 1000  to convert from grams to milligrams
MyDF <- MyDF %>% rowwise() %>% mutate(Prey.mass = 
                                        ifelse(Prey.mass.unit == "mg", Prey.mass/1000, Prey.mass))

## calculate reg results for fitted lines in each subset of data 
LinearOutput2 <- dlply(MyDF,.(Type.of.feeding.interaction, Predator.lifestage, Location), function(x) lm(Predator.mass~Prey.mass, data = x))

# Extract Coeffieciets r2, intercept, slope and p value
CoefOut2 <- ldply (LinearOutput2, function(x) {
  intercept <- summary(x)$coefficients[1]
  slope <- summary(x)$coefficients[2]
  p.value <- summary(x)$coefficients[8]
  r2 <- summary(x)$r.squared
  data.frame(r2, intercept, slope, p.value)})

# Extract F statistic
F.statistic2 <- ldply(LinearOutput2, function(x) summary(x)$fstatistic[1])

# Merge F stat with rest of coefficients into one dataframe
OutputDF2 <- merge(CoefOut2, F.statistic2, by = c("Type.of.feeding.interaction", "Predator.lifestage", "Location"), all = TRUE)

# change name of 7th columm
names(OutputDF2)[7] <- "F.statistic"
OutputDF2
# write results to a csv file in the results directory 
write.csv(OutputDF2, "../Results/PP_Regress_loc_Results.csv", row.names = FALSE, quote = FALSE)
**********************************************************************

Testing PP_Regress_loc.R...

Output (only first 500 characters): 

**********************************************************************
   Type.of.feeding.interaction Predator.lifestage
1                insectivorous   larva / juvenile
2                  piscivorous              adult
3                  piscivorous              adult
4                  piscivorous              adult
5                  piscivorous              adult
6                  piscivorous              adult
7                  piscivorous              adult
8                  piscivorous              adult
9                  piscivorous              adult
1
**********************************************************************

Encountered error:

Attaching package: ‘dplyr’

The following objects are masked from ‘package:plyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning messages:
1: In summary.lm(x) : essentially perfect fit: summary may be unreliable
2: In summary.lm(x) : essentially perfect fit: summary may be unreliable
3: In summary.lm(x) : essentially perfect fit: summary may be unreliable
4: In summary.lm(x) : essentially perfect fit: summary may be unreliable
Warning message:
In summary.lm(x) : essentially perfect fit: summary may be unreliable

======================================================================
Inspecting script file DataWrang.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Wrangling data with base R and reshape2 package

rm(list=ls()) # clears workspace
graphics.off() # clear graphics

################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../Data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../Data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
head(MyData) # prints first 6 rows and headers
dim(MyData) # prints dimensions
str(MyData) # prints structure
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

rownames(TempData) <- NULL  # removes row names
head(TempData)

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")
head(MyWrangledData); tail(MyWrangledData)
# melt collapses daat in wide format and stacks it into singl column

# assign he correct data type of each row
MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])
#as.factor creates a factor column

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

# from plyr to dplyr
# from reshape2 to tidyr

require(dplyr)
require(tidyr)

dplyr::tbl_df(MyWrangledData) #like head()
dplyr::glimpse(MyWrangledData) #like str()
utils::View(MyWrangledData) #same as fix()
dplyr::filter(MyWrangledData, Count > 100) #like subset()
dplyr::slice(MyWrangledData, 10:15) # Look at an arbitrary set of data rows
dplyr::tbl_df(MyData)
**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 

**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Code ran without errors

Time consumed = 10.00647s

======================================================================
Inspecting script file TAutoCorr.tex...

File contents are:
**********************************************************************
\documentclass[12pt]{article}
\title{Time Series Autocorrelation of Key West Yearly Mean Tempertures (1901 - 2000)}
\usepackage{graphicx}
\author{David Scott}
\date{24/10/2018}
\begin{document}
    \maketitle

    \begin{abstract}
        To determine if mean temperature data are significantly correlated with the succesive across time (years) in Key West, Florida. 
        Time series used included data from the year 1901 to 2000. A lag -1 autocorrelation was used and gave a weak r score of 0.326. Random permutated pairs were also 
        generated from the data ten thousand times and tested. This created a random sample to test initial correlation result against. the fraction of these 
        that were greater than intiial correlation was 4e-04. This suggests correlation was non-random. Thus the effect from year to year was significant but weak.  
    \end{abstract} 

    \section{Introduction}
        In class exercise to investigate if mean temperatures from one year are
        significantly correlated with the successive year. 
        Autocorrelation examines data as pairs asseses if a time series is 
        dependent on its past. Pairs of data take form of:
        \begin{equation}
        (x[t],x[t-1]) \  \
        t = observation index. 
        \end{equation}
        Estimated sample correlation of these pairs is the lag -1 autocorrelation. 

    \section{Methodology}
        To calculate the lag -1 autocorrelation, a time series of yearly mean temperatures collected in Key West, 
        Florida from the year 1901 to 2000. This data was imported into RStudio environment. 
        An initial correlation score was calculated using each succesive pair in the sequence. 
        Subsequently repeated calculation ten thousand times by randomly permutating the time series and
        the correlation coefficient was recalculated for each year sequence. Finally the 
        fraction of the ten thousand correlation coefficient that were greater than the 
        initial autocorrelation was calculated as a p value. 

    \section{Results}
        From the initial correlation, an estimated lag-1 autocorrelation
        score of 0.326 was calculated. This is represented by the red 
        abline in figure 1. The autocorrelations generated through 
        the random permutations are displayed as a histogram in figure 1. The fraction of 
        these that were than 0.326 was 4e-04. The abline suggests 
        in figure 1 the intial correlation result falls within the 5% confidence interval. 
        
            \begin{figure}[!h]
            \begin{center}
            \includegraphics[width=8cm]{../Results/Rplot.png}
            \caption{Frequency of autocorrelations generated from 10,000 random permutations of Key West yearly mean temperature data. 
                Includes abline (red) of autocorrelation of one single correlation of succesive years}
            \end{center}
            \end{figure}

    \section{Discussion}
        In examining figure 1, it is 95\% confident that the first autocorrelation is non-random. 
        This is supported by a significantly low p-value. This suggest that
        the temperature is significantly impacted by the previous year but the impact recorded is weak. 

    \end{document}
**********************************************************************

Testing TAutoCorr.tex...

======================================================================
Inspecting script file MyBars.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 29 2018
# Description: Annotating Histogram

rm(list = ls()) 
graphics.off() 

#Packages 
library(ggplot2)

a <- read.table("../Data/Results.txt", header = TRUE)

head(a)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
    x = x,
    ymin = ymin,
    ymax = y1,
    size = (0.5)),
    colour = "#E69F00",
    alpha = 1/2, show.legend = FALSE)
  
# Print the second linerange
p <- p + geom_linerange(data = a, aes(
  x = x,
  ymin = ymin,
  ymax = y2,
  size = (0.5)
),
colour = "#56B4E9",
alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
  x = x,
  ymin = ymin,
  ymax = y3,
  size = (0.5)
),
colour = "#D55E00",
alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
  scale_y_continuous("My y axis") + 
  theme_bw() + 
  theme(legend.position = "none") 

# Open blank pdf page using a relative path
pdf("../Results/MyBars.pdf") 
print(p)
graphics.off() 
**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 

**********************************************************************
         x   y1   y2 y3 Label
1 3.515424 4320 4320  0  <NA>
2 3.533984 2160 2160  0  <NA>
3 3.557647 4320 4320  0  <NA>
4 3.569953 4320 4320  0  <NA>
5 3.578984 8640 8640  0  <NA>
6 3.585665 2160 2160  0  <NA>

**********************************************************************

Encountered error:
Warning message:
Removed 91 rows containing missing values (geom_text). 

======================================================================
Inspecting script file GPDDmap.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Creates a world map and plots data points using maps package

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

## packages ##
library(maps) # loads maps package

### load data from Data directory
load("../Data/GPDDFiltered.RData") 

### lattitude data
lat <- gpdd[,2] # comma puts columns and not default row 
# lattitude data assigned to variable lat
#print("The Latitude coordinates are:")
#print(lat)

### longitude data 
long <- gpdd[,3] # comma puts columns and not default row 
#print("The Longitudinal coordinates are:")
#print(long) # longitude data assigned to variable long

### map of world
map("world", fill=TRUE, col="white", bg="lightblue", ylim=c(-60, 90), mar=c(0,0,0,0))
# map funtions creates a base map of the "world". 
points(long, lat, col="purple", pch=16)
# points funtion plots location of species using longitude (long) and latitude (lat)
#  data on world map previous created

### ANSWER ###
# most of the data is in the western countries.
# In europe, cluster occurs in Britain. 
# Also within countries where sampling occurs there are clusters observed.
# for example USA, dense clustering occurs along west coast as compared 
# with the other regions, such as the east coast, southern and mid western states. 
# Thus there is a strong sample bias and is therefore not representative 
# of global vertebrate populations. 
**********************************************************************

Testing GPDDmap.R...

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error:
Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
Calls: load -> readChar
In addition: Warning message:
In readChar(con, 5L, useBytes = TRUE) :
  cannot open compressed file '../Data/GPDDFiltered.RData', probable reason 'No such file or directory'
Execution halted

======================================================================
Inspecting script file control.R...

File contents are:
**********************************************************************
#!/usr/bin/env Rscript
# Author: David Scott
# Contact: david.scott18@imperial.ac.uk
# Date:  October 24 2018
# Description: Example of control flow constructs in R

rm(list=ls()) # clears workspace
graphics.off() # clears graphics

## Some code exemplifying control flow constructs in R

## If statement
a <- TRUE
if (a == TRUE){
    print ("a is TRUE")
    } else {
    print ("a is FALSE")
}

## On a single line
z <- runif(1) ##random number
if (z <= 0.5) {
    print ("Less than a quarter")
    }

## For loop using a sequence 
for (i in 1:100){
    j <- i * i
    print(paste(i, " squared is", j ))
    }

## For loop over vector of strings
for(species in c('Heliodoxa rubinoides', 
                'Boissonneaua jardini',
                'Sula nebouxii'))
{
    print(paste('The species is', species))
}

## for loop using a vector
v1 <- c("a", "bc", "def")
for (i in v1){
    print(i)
}

## While loop 
i <- 0
while (i<100){
    i <- i+1
    print(i^2)
}
**********************************************************************

Testing control.R...

Output (only first 500 characters): 

**********************************************************************
[1] "a is TRUE"
[1] "Less than a quarter"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "11  squared is 121"
[1] "12  squared is 144"
[1] "13  squared is 169"
[1] "14  squared is 196"
[1] "15  squared is 225"
[1] "16  squared is 256"
[1] "17  squared is 289"
[1] "18  squared is 324"
[1] "19  squared is 361"
[1] "
**********************************************************************

Code ran without errors

Time consumed = 0.09261s

======================================================================
Inspecting script file Run_Vectorize.sh...

File contents are:
**********************************************************************
#!/bin/bash
# Author: David Scott David.Scott18@imperial.ac.uk
# Script: boilerplate.sh
# Desc: Compares speed of functions with and without vectorization(R & Python)
# Arguments: none
# Date: Oct 2018

divider===============================
divider=$divider$divider
width=60

printf "%$width.${width}s\n" "$divider"

echo -e "Running Vectorize1.R  in R .... \n"
time Rscript --vanilla Vectorize1.R 
echo -e "^^ Run time of Vectorize1.R script. \n"
echo -e "Vectorize1.R is complete. \n"

printf "%$width.${width}s\n" "$divider"

echo -e  "Running Vectorize1.py in python3 .... \n"
time python3 Vectorize1.py
echo -e "^^ Run time of Vectorize1.py script. \n"
echo -e  "Vectorize1.py is complete. \n"

printf "%$width.${width}s\n" "$divider"

echo -e "Running Vectorize2.R  in R .... \n"
time Rscript --vanilla Vectorize2.R
echo -e "^^ Run time of Vectorize2.R script. \n"
echo -e "Vectorize2.R is complete. \n"

printf "%$width.${width}s\n" "$divider"

echo -e "Running Vectorize2.py in python3 .... \n"
time python3 Vectorize2.py
echo -e "^^ Run time of Vectorize2.py script. \n"
echo -e "Vectorize2.py is complete.\n"

printf "%$width.${width}s\n" "$divider"
**********************************************************************

Testing Run_Vectorize.sh...

Output (only first 500 characters): 

**********************************************************************
============================================================
Running Vectorize1.R  in R .... 

[1] "Speed of SumAllElements function defined using loops:"
   user  system elapsed 
  0.076   0.004   0.082 
[1] "Speed of sum function without loops:"
   user  system elapsed 
  0.000   0.000   0.001 
^^ Run time of Vectorize1.R script. 

Vectorize1.R is complete. 

============================================================
Running Vectorize1.py in python3 .... 

Speed of SumAllElements function usi
**********************************************************************

Encountered error:

real	0m0.222s
user	0m0.184s
sys	0m0.028s

real	0m0.333s
user	0m0.400s
sys	0m0.220s

real	0m0.339s
user	0m0.332s
sys	0m0.004s

real	0m0.133s
user	0m0.200s
sys	0m0.228s

======================================================================
======================================================================
Finished running scripts

Ran into 11 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 100

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!